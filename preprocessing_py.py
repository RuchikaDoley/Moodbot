# -*- coding: utf-8 -*-
"""preprocessing.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1g2JCoYwoDKr_okiuR_JmYvEp7JHCHIS4
"""

pip install tensorflow pandas numpy scikit-learn nltk matplotlib nlpaug

import pandas as pd
import numpy as np
import re
import nltk
import matplotlib.pyplot as plt
import seaborn as sns

from nltk.corpus import stopwords
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping

# Download necessary NLTK resources
nltk.download('stopwords')

stop_words = set(stopwords.words('english'))

df = pd.read_csv("emotion_dataset.csv", names=["sentence", "emotion"])

print(df.head())
print(df['emotion'].value_counts())  # Check class distribution

def preprocess_text(text):
    text = text.lower()  # Convert to lowercase
    text = re.sub(r'[^\w\s]', '', text)  # Remove punctuation
    text = ' '.join([word for word in text.split() if word not in stop_words])  # Remove stopwords
    return text

df['cleaned_sentence'] = df['sentence'].apply(preprocess_text)

sns.countplot(x=df["emotion"])
plt.title("Emotion Class Distribution")
plt.show()

df = df[df['emotion'] != 'emotion']
sns.countplot(x=df["emotion"])
plt.title("Final Emotion Class Distribution After Dropping")
plt.xticks(rotation=45)
plt.show()

pip install imbalanced-learn

from imblearn.over_sampling import SMOTE
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split

# Convert text to numerical format using TF-IDF
vectorizer = TfidfVectorizer(max_features=5000)  # Keeping top 5000 words
X_tfidf = vectorizer.fit_transform(df['cleaned_sentence'])

# Encode labels
label_encoder = LabelEncoder()
df['emotion_encoded'] = label_encoder.fit_transform(df['emotion'])

# Apply SMOTE for class balancing
smote = SMOTE(sampling_strategy='auto', random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_tfidf, df['emotion_encoded'])

# Convert back to DataFrame
df_balanced = pd.DataFrame(X_resampled.toarray(), columns=vectorizer.get_feature_names_out())
df_balanced['emotion'] = label_encoder.inverse_transform(y_resampled)

# Print new class distribution
print(df_balanced['emotion'].value_counts())

# Updated bar plot after SMOTE
sns.countplot(x=df_balanced["emotion"])
plt.title("Balanced Emotion Class Distribution")
plt.xticks(rotation=45)
plt.show()

X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)

from sklearn.naive_bayes import MultinomialNB

# Initialize and train the model
nb_model = MultinomialNB()
nb_model.fit(X_train, y_train)

from sklearn.metrics import accuracy_score, classification_report

# Predictions
y_pred = nb_model.predict(X_test)

# Model evaluation
print(f"Accuracy: {accuracy_score(y_test, y_pred):.4f}")
print("Classification Report:\n", classification_report(y_test, y_pred, target_names=label_encoder.classes_))

